import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Function to load data from uploaded files
@st.cache_data
def load_data(file):
    return pd.read_csv(file)

# Function to preprocess data
def preprocess_data(sales_data, comparison_data_unique):
    sales_data.columns = sales_data.columns.str.strip().str.lower().str.replace(' ', '_')
    comparison_data_unique.columns = comparison_data_unique.columns.str.strip().str.lower().str.replace(' ', '_')
    
    sales_data['itemname'] = sales_data['itemname'].str.strip().str.lower()
    comparison_data_unique['itemname'] = comparison_data_unique['itemname'].str.strip().str.lower()
    
    sales_data['total_weight'] = sales_data['item_quantity'] * sales_data['item_total']
    merged_data = pd.merge(sales_data, comparison_data_unique, on='itemname', how='left')
    merged_data.drop(['order_date', 'order_time', 'order_id', 'reference_number', 'order_source',
                      'sub_total', 'total_merchant_tax', 'total_tax', 'total_discount', 'net_payable',
                      'item_total', 'item_discount', 'item_taxes'], axis=1, inplace=True)
    
    ingredient_totals = merged_data.groupby('ingredients')['total_weight'].sum().reset_index()
    ingredient_totals['unit'] = 'grams'
    ingredient_totals.rename(columns={'ingredients': 'INGREDIENTS', 'total_weight': 'Total Ingredient Weight'}, inplace=True)
    
    return ingredient_totals

# Function to perform sales data analysis
def analyze_sales_data(sales_data):
    # Ensure correct column names
    sales_data.columns = sales_data.columns.str.strip().str.lower().str.replace(' ', '_')
    
    food_item_sales = sales_data.groupby('itemname').agg({
        'item_quantity': 'sum',
        'sub_total': 'sum'
    }).reset_index()

    best_selling_by_quantity = food_item_sales.loc[food_item_sales['item_quantity'].idxmax()]
    best_selling_by_revenue = food_item_sales.loc[food_item_sales['sub_total'].idxmax()]
    average_quantity_sold = food_item_sales['item_quantity'].mean()
    average_revenue = food_item_sales['sub_total'].mean()
    top_3_least_selling_by_quantity = food_item_sales.nsmallest(3, 'item_quantity')
    top_3_least_selling_by_revenue = food_item_sales.nsmallest(3, 'sub_total')

    return food_item_sales, best_selling_by_quantity, best_selling_by_revenue, average_quantity_sold, average_revenue, top_3_least_selling_by_quantity, top_3_least_selling_by_revenue

# Function to visualize data
def visualize_data(food_item_sales):
    plt.figure(figsize=(20, 20))
    sns.barplot(x='item_quantity', y='itemname', data=food_item_sales, palette='Blues_r', dodge=False)
    plt.xlabel('Quantity Sold')
    plt.ylabel('Food Item')
    plt.title('Quantity Sold of Food Items')
    plt.grid(axis='x')
    st.pyplot(plt)
    
    plt.figure(figsize=(20, 20))
    sns.barplot(x='sub_total', y='itemname', data=food_item_sales, palette='Greens_r', dodge=False)
    plt.xlabel('Revenue Generated')
    plt.ylabel('Food Item')
    plt.title('Revenue Generated by Food Items')
    plt.grid(axis='x')
    st.pyplot(plt)

# Function to predict ingredient weight using Random Forest
def predict_ingredient_weight(ingredient_data):
    # Ensure correct column names
    ingredient_data.columns = ingredient_data.columns.str.strip().str.lower().str.replace(' ', '_')

    # Check if 'weightage' column exists
    if 'weightage' not in ingredient_data.columns or 'cost' not in ingredient_data.columns:
        st.error("Columns 'weightage' or 'cost' not found in the uploaded data.")
        return

    # Convert 'weightage' and 'cost' to numeric values, coerce errors
    ingredient_data['weightage'] = pd.to_numeric(ingredient_data['weightage'], errors='coerce')
    ingredient_data['cost'] = pd.to_numeric(ingredient_data['cost'], errors='coerce')

    # Drop rows with NaN values in 'weightage' or 'cost' columns
    ingredient_data = ingredient_data.dropna(subset=['weightage', 'cost'])

    X = ingredient_data[['weightage']]
    y = ingredient_data['cost']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model_pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('regressor', RandomForestRegressor(random_state=42))
    ])

    param_grid = {
        'regressor__n_estimators': [100, 150, 200],
        'regressor__max_depth': [None, 10, 20],
        'regressor__min_samples_split': [2, 5],
        'regressor__min_samples_leaf': [1, 2]
    }

    grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, error_score='raise')
    grid_search.fit(X_train, y_train)

    y_pred = grid_search.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    plt.figure(figsize=(10, 6))
    sns.histplot(y_test, color='blue', label='Actual', kde=True)
    sns.histplot(y_pred, color='red', label='Predicted', kde=True)
    plt.title('Distribution of Actual vs Predicted Values')
    plt.xlabel('Total Ingredient Weight (kg)')
    plt.ylabel('Count')
    plt.legend()
    plt.grid(True)
    st.pyplot(plt)
    
    plt.figure(figsize=(8, 8))
    plt.scatter(y_test, y_pred, color='blue', alpha=0.7)
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')
    plt.title('Actual vs Predicted Values')
    plt.xlabel('Actual Total Ingredient Weight (kg)')
    plt.ylabel('Predicted Total Ingredient Weight (kg)')
    plt.grid(True)
    st.pyplot(plt)

    return {
        "MAE": mae,
        "MSE": mse,
        "RMSE": rmse,
        "R2": r2
    }

def main():
    st.title("Sales and Ingredient Data Analysis")

    sales_file = st.file_uploader("Upload Sales Data CSV", type=["csv"])
    ingredients_file = st.file_uploader("Upload Ingredients Data CSV", type=["csv"])
    
    if sales_file is not None and ingredients_file is not None:
        if st.button('Submit'):
            with st.spinner('Processing...'):
                sales_data = load_data(sales_file)
                comparison_data_unique = load_data(ingredients_file)
                
                # Preprocess and analyze data
                ingredient_totals = preprocess_data(sales_data, comparison_data_unique)
                food_item_sales, best_selling_by_quantity, best_selling_by_revenue, average_quantity_sold, average_revenue, top_3_least_selling_by_quantity, top_3_least_selling_by_revenue = analyze_sales_data(sales_data)
                
                st.subheader("Ingredient Totals")
                st.write(ingredient_totals)

                st.subheader("Sales Data Analysis")
                st.write("Best Selling Food Item by Quantity Sold:", best_selling_by_quantity)
                st.write("Best Selling Food Item by Revenue:", best_selling_by_revenue)
                st.write(f"Average Quantity Sold: {average_quantity_sold:.2f}")
                st.write(f"Average Revenue: {average_revenue:.2f}")
                st.write("Top 3 Least Selling Food Items by Quantity Sold:", top_3_least_selling_by_quantity)
                st.write("Top 3 Least Selling Food Items by Revenue:", top_3_least_selling_by_revenue)

                visualize_data(food_item_sales)
                
                st.subheader("Random Forest Prediction of Ingredient Weight")
                prediction_results = predict_ingredient_weight(comparison_data_unique)
                st.write(prediction_results)

if __name__ == "__main__":
    main()
